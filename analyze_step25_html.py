#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†ææ­¥éª¤25ä¿å­˜çš„HTMLæ–‡ä»¶ï¼ŒæŸ¥æ‰¾è¡¨æ ¼æ•°æ®
"""

import sys
import re
from pathlib import Path
from bs4 import BeautifulSoup
import pandas as pd

def analyze_html_file(html_file):
    """åˆ†æHTMLæ–‡ä»¶ï¼ŒæŸ¥æ‰¾è¡¨æ ¼æ•°æ®"""
    
    print("=" * 60)
    print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {html_file.name}")
    print("=" * 60)
    
    try:
        with open(html_file, "r", encoding="utf-8") as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # 1. æŸ¥æ‰¾è¡¨æ ¼å…ƒç´ 
        print("\nğŸ” æŸ¥æ‰¾è¡¨æ ¼å…ƒç´ ...")
        tables = soup.find_all('table')
        print(f"æ‰¾åˆ° {len(tables)} ä¸ªè¡¨æ ¼")
        
        for i, table in enumerate(tables):
            print(f"\nğŸ“Š è¡¨æ ¼ {i}:")
            
            # æŸ¥æ‰¾è¡¨å¤´
            headers = []
            thead = table.find('thead')
            if thead:
                header_cells = thead.find_all(['th', 'td'])
                headers = [cell.get_text().strip() for cell in header_cells]
                print(f"  è¡¨å¤´ï¼ˆä»theadï¼‰: {headers}")
            else:
                # å°è¯•ä»ç¬¬ä¸€è¡Œè·å–è¡¨å¤´
                first_row = table.find('tr')
                if first_row:
                    header_cells = first_row.find_all(['th', 'td'])
                    headers = [cell.get_text().strip() for cell in header_cells]
                    print(f"  è¡¨å¤´ï¼ˆä»ç¬¬ä¸€è¡Œï¼‰: {headers}")
            
            # æŸ¥æ‰¾æ•°æ®è¡Œ
            tbody = table.find('tbody')
            if tbody:
                rows = tbody.find_all('tr')
            else:
                rows = table.find_all('tr')[1:]  # è·³è¿‡è¡¨å¤´è¡Œ
            
            print(f"  æ•°æ®è¡Œæ•°: {len(rows)}")
            
            # æå–å‰3è¡Œæ•°æ®ä½œä¸ºç¤ºä¾‹
            if rows:
                print(f"  å‰3è¡Œæ•°æ®:")
                for j, row in enumerate(rows[:3]):
                    cells = row.find_all(['td', 'th'])
                    row_data = [cell.get_text().strip() for cell in cells]
                    print(f"    è¡Œ {j+1}: {row_data}")
            
            # å°è¯•æå–å®Œæ•´è¡¨æ ¼æ•°æ®
            try:
                table_data = []
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    row_dict = {}
                    for k, cell in enumerate(cells):
                        if k < len(headers):
                            row_dict[headers[k]] = cell.get_text().strip()
                        else:
                            row_dict[f"column_{k}"] = cell.get_text().strip()
                    if row_dict:
                        table_data.append(row_dict)
                
                if table_data:
                    print(f"\n  âœ… æˆåŠŸæå– {len(table_data)} è¡Œæ•°æ®")
                    
                    # ä¿å­˜ä¸ºExcel
                    df = pd.DataFrame(table_data)
                    output_file = html_file.parent / f"{html_file.stem}_extracted.xlsx"
                    df.to_excel(output_file, index=False)
                    print(f"  ğŸ’¾ å·²ä¿å­˜åˆ°: {output_file.name}")
                    
                    # æ˜¾ç¤ºåˆ—ç»Ÿè®¡
                    print(f"\n  ğŸ“Š åˆ—ç»Ÿè®¡:")
                    for col in df.columns:
                        non_empty = df[col].astype(str).str.strip().ne('').sum()
                        print(f"    {col}: {non_empty}/{len(df)} è¡Œæœ‰æ•°æ®")
                    
            except Exception as e:
                print(f"  âŒ æå–è¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
        
        # 2. æŸ¥æ‰¾Markdownè¡¨æ ¼
        print("\nğŸ” æŸ¥æ‰¾Markdownè¡¨æ ¼...")
        text_content = soup.get_text()
        
        # æŸ¥æ‰¾Markdownè¡¨æ ¼æ ¼å¼ï¼ˆ|åˆ†éš”ï¼‰
        markdown_lines = [line for line in text_content.split('\n') if '|' in line]
        if markdown_lines:
            print(f"æ‰¾åˆ° {len(markdown_lines)} è¡ŒåŒ…å« | çš„æ–‡æœ¬")
            print(f"å‰5è¡Œ:")
            for line in markdown_lines[:5]:
                print(f"  {line.strip()}")
        
        # 3. æŸ¥æ‰¾CSVæ ¼å¼
        print("\nğŸ” æŸ¥æ‰¾CSVæ ¼å¼...")
        csv_lines = [line for line in text_content.split('\n') if ',' in line and len(line.split(',')) > 3]
        if csv_lines:
            print(f"æ‰¾åˆ° {len(csv_lines)} è¡Œå¯èƒ½çš„CSVæ•°æ®")
            print(f"å‰5è¡Œ:")
            for line in csv_lines[:5]:
                print(f"  {line.strip()}")
        
        # 4. æŸ¥æ‰¾ä»£ç å—ä¸­çš„è¡¨æ ¼
        print("\nğŸ” æŸ¥æ‰¾ä»£ç å—ä¸­çš„è¡¨æ ¼...")
        code_blocks = soup.find_all(['pre', 'code'])
        print(f"æ‰¾åˆ° {len(code_blocks)} ä¸ªä»£ç å—")
        
        for i, block in enumerate(code_blocks):
            text = block.get_text()
            if '|' in text or ',' in text:
                print(f"\n  ä»£ç å— {i} å¯èƒ½åŒ…å«è¡¨æ ¼æ•°æ®:")
                print(f"    é•¿åº¦: {len(text)} å­—ç¬¦")
                print(f"    é¢„è§ˆ: {text[:200]}...")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” æ­¥éª¤25 HTMLåˆ†æå·¥å…·")
    print("=" * 60)
    
    # æŸ¥æ‰¾æ‰€æœ‰æ­¥éª¤25çš„HTMLæ–‡ä»¶
    process_folder = Path("assets/Process_Folder")
    html_files = list(process_folder.glob("**/debug/step_25_response_*.html"))
    
    if not html_files:
        print("\nâŒ æœªæ‰¾åˆ°æ­¥éª¤25çš„HTMLæ–‡ä»¶")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ video_automation.py æˆ–æµ‹è¯•è„šæœ¬ï¼Œå¹¶ç¡®ä¿ SAVE_DEBUG_HTML = True")
        return
    
    print(f"\nğŸ“‹ æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
    
    # åˆ†ææœ€æ–°çš„æ–‡ä»¶
    latest_file = max(html_files, key=lambda f: f.stat().st_mtime)
    print(f"\nğŸ“„ åˆ†ææœ€æ–°çš„æ–‡ä»¶: {latest_file.relative_to(process_folder)}")
    
    analyze_html_file(latest_file)
    
    print("\n" + "=" * 60)
    print("âœ… åˆ†æå®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†ä¾èµ–
    try:
        from bs4 import BeautifulSoup
        import pandas as pd
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¿è¡Œ: pip install beautifulsoup4 pandas openpyxl")
        sys.exit(1)
    
    main()
