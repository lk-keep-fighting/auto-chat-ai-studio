#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†ææ­¥éª¤23ä¿å­˜çš„HTMLæ–‡ä»¶ï¼ŒæŸ¥æ‰¾SRTå†…å®¹å’Œä¸‹è½½æŒ‰é’®
"""

import sys
import re
from pathlib import Path
from bs4 import BeautifulSoup

def analyze_html_file(html_file):
    """åˆ†æHTMLæ–‡ä»¶ï¼ŒæŸ¥æ‰¾SRTç›¸å…³å†…å®¹"""
    
    print("=" * 60)
    print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {html_file.name}")
    print("=" * 60)
    
    try:
        with open(html_file, "r", encoding="utf-8") as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # 1. æŸ¥æ‰¾ä»£ç å—
        print("\nğŸ” æŸ¥æ‰¾ä»£ç å—...")
        code_blocks = soup.find_all(['pre', 'code'])
        print(f"æ‰¾åˆ° {len(code_blocks)} ä¸ªä»£ç å—")
        
        for i, block in enumerate(code_blocks):
            text = block.get_text()
            if '-->' in text and re.search(r'\d{2}:\d{2}:\d{2},\d{3}', text):
                print(f"\nâœ… ä»£ç å— {i} åŒ…å«SRTå†…å®¹:")
                print(f"  é•¿åº¦: {len(text)} å­—ç¬¦")
                print(f"  é¢„è§ˆ: {text[:200]}...")
        
        # 2. æŸ¥æ‰¾ä¸‹è½½æŒ‰é’®
        print("\nğŸ” æŸ¥æ‰¾ä¸‹è½½æŒ‰é’®...")
        download_buttons = soup.find_all('button', attrs={'aria-label': re.compile(r'download', re.I)})
        print(f"æ‰¾åˆ° {len(download_buttons)} ä¸ªä¸‹è½½æŒ‰é’®")
        
        for i, button in enumerate(download_buttons):
            print(f"\næŒ‰é’® {i}:")
            print(f"  aria-label: {button.get('aria-label')}")
            print(f"  class: {button.get('class')}")
            
            # æŸ¥æ‰¾æŒ‰é’®é™„è¿‘çš„å†…å®¹
            parent = button.parent
            if parent:
                parent_text = parent.get_text()
                if '-->' in parent_text:
                    print(f"  âœ… çˆ¶å…ƒç´ åŒ…å«SRTå†…å®¹")
                    print(f"  é•¿åº¦: {len(parent_text)} å­—ç¬¦")
        
        # 3. æŸ¥æ‰¾æ‰€æœ‰åŒ…å«SRTæ—¶é—´æˆ³çš„å…ƒç´ 
        print("\nğŸ” æŸ¥æ‰¾åŒ…å«SRTæ—¶é—´æˆ³çš„å…ƒç´ ...")
        all_text = soup.get_text()
        
        # æŸ¥æ‰¾æ‰€æœ‰æ—¶é—´æˆ³
        timestamps = re.findall(r'\d{2}:\d{2}:\d{2},\d{3}\s+-->\s+\d{2}:\d{2}:\d{2},\d{3}', all_text)
        print(f"æ‰¾åˆ° {len(timestamps)} ä¸ªæ—¶é—´æˆ³")
        
        if timestamps:
            print(f"  ç¬¬ä¸€ä¸ª: {timestamps[0]}")
            print(f"  æœ€åä¸€ä¸ª: {timestamps[-1]}")
        
        # 4. æŸ¥æ‰¾åŒ…å«class="code"æˆ–ç±»ä¼¼çš„å…ƒç´ 
        print("\nğŸ” æŸ¥æ‰¾åŒ…å«'code'ç±»åçš„å…ƒç´ ...")
        code_elements = soup.find_all(class_=re.compile(r'code', re.I))
        print(f"æ‰¾åˆ° {len(code_elements)} ä¸ªå…ƒç´ ")
        
        for i, elem in enumerate(code_elements[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            text = elem.get_text()
            if '-->' in text:
                print(f"\nâœ… å…ƒç´  {i} åŒ…å«SRTå†…å®¹:")
                print(f"  æ ‡ç­¾: {elem.name}")
                print(f"  class: {elem.get('class')}")
                print(f"  é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # 5. æå–å®Œæ•´çš„SRTå†…å®¹
        print("\nğŸ” å°è¯•æå–å®Œæ•´çš„SRTå†…å®¹...")
        
        # æ–¹æ³•1ï¼šä»ç¬¬ä¸€ä¸ªæ—¶é—´æˆ³å¼€å§‹æå–
        match = re.search(r'(\d+\s+\d{2}:\d{2}:\d{2},\d{3}\s+-->.*)', all_text, re.DOTALL)
        if match:
            srt_content = match.group(1)
            print(f"âœ… æå–åˆ°SRTå†…å®¹:")
            print(f"  é•¿åº¦: {len(srt_content)} å­—ç¬¦")
            print(f"  å‰200å­—ç¬¦: {srt_content[:200]}...")
            
            # ä¿å­˜æå–çš„å†…å®¹
            output_file = html_file.parent / f"{html_file.stem}_extracted.srt"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(srt_content)
            print(f"  ğŸ’¾ å·²ä¿å­˜åˆ°: {output_file.name}")
        else:
            print("âŒ æœªæ‰¾åˆ°SRTå†…å®¹")
        
        # 6. æŸ¥æ‰¾æ‰€æœ‰æŒ‰é’®
        print("\nğŸ” æŸ¥æ‰¾æ‰€æœ‰æŒ‰é’®...")
        all_buttons = soup.find_all('button')
        print(f"æ‰¾åˆ° {len(all_buttons)} ä¸ªæŒ‰é’®")
        
        button_labels = {}
        for button in all_buttons:
            label = button.get('aria-label', 'no-label')
            button_labels[label] = button_labels.get(label, 0) + 1
        
        print("æŒ‰é’®æ ‡ç­¾ç»Ÿè®¡:")
        for label, count in sorted(button_labels.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  {label}: {count}")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” æ­¥éª¤23 HTMLåˆ†æå·¥å…·")
    print("=" * 60)
    
    # æŸ¥æ‰¾æ‰€æœ‰æ­¥éª¤23çš„HTMLæ–‡ä»¶
    process_folder = Path("assets/Process_Folder")
    html_files = list(process_folder.glob("**/debug/step_23_response_*.html"))
    
    if not html_files:
        print("\nâŒ æœªæ‰¾åˆ°æ­¥éª¤23çš„HTMLæ–‡ä»¶")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ video_automation.py å¹¶ç¡®ä¿ SAVE_DEBUG_HTML = True")
        return
    
    print(f"\nğŸ“‹ æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
    
    # åˆ†ææœ€æ–°çš„æ–‡ä»¶
    latest_file = max(html_files, key=lambda f: f.stat().st_mtime)
    print(f"\nğŸ“„ åˆ†ææœ€æ–°çš„æ–‡ä»¶: {latest_file.relative_to(process_folder)}")
    
    analyze_html_file(latest_file)
    
    print("\n" + "=" * 60)
    print("âœ… åˆ†æå®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦å®‰è£…äº† beautifulsoup4
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… beautifulsoup4")
        print("è¿è¡Œ: pip install beautifulsoup4")
        sys.exit(1)
    
    main()
